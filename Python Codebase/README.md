# CovidFighter Python Scripts

CovidFighter uses the following files which are scheduled to run at specific intervals in order to generate the daily predictions for new cases and economic impact

## masterdata_etl.py

* This script is scheduled to run daily
* If the date is 2020-11-17, then data until the day before is persisted as 'MasterData_2020-11-16_final.csv' in the 'data' folder
* The script fetches all necessary data metrics for the current day and appends the data to 'MasterData_2020-11-16_final.csv' and generates 'MasterData_2020-11-17_final.csv' in the 'data' folder
* This MasterData file is utilized by both model.py for training the model and daily_scoring.py for generating daily predictions


## model.py

* This script is scheduled to run fortnightly
* If the date is 2020-11-15, then it will use 'MasterData_2020-11-15_final.csv' for training
* The script trains models for all specified states separately for: a) Daily New Cases prediction b) Small Business Revenue Change (%) prediction
* The trained models are saved in the 'models' folder. Each state has 2 model e.g. New York has: a) NewYork_v1.joblib b) NewYork_v1_OIET_WomplyRevenue_RevenueAll.joblib
* With each training cycle the model version is increased so 'NewYork_v1.joblib' is incremented to 'NewYork_v2.joblib'. The latest version value is persisted in 'config.joblib' in the 'data' folder 
* The script also generates backtesting for the last 2 week horizon as a measure of model's predicitive power. If the script is run on 2020-11-15 the backtested results are saved as 'backTest_14days_on_2020-11-15.csv' in the 'models' folder
* A feature dictionary containing the input features for each state's Daily New Cases model is saved as 'feature_dictionary_v1.joblib' in the 'models' folder with the version increasing with every iteration. Similarly, 'eco_model_dictionaryv1.joblib' and 'eco_feature_dictionaryv1.joblib' contain the economic model's name and corresponding features for each state
* The script also contains feature importance calculation using the LIME algorithm (experimental feature at present with enhancement planned later using SHAP). The most important (human controllable) features for each state are curated and persisted in 'Sim_Vars_State.csv' in the 'models' folder. These features are used by daily_scoring.py for simulating scenarios like Govt. policies
* Because of errors resulting in attempting to train Voting Regressors on C3.ai we have reverted to vanilla scikit-learn for this iteration

## daily_scoring.py

* This script is scheduled to run daily
* If the date is 2020-11-17, then it will use 'MasterData_2020-11-17_final.csv' for generating predictions
* It leverages the models and the dictionaries generated by model.py in order to calculate the predictions
* The latest version of the models is read from 'config.joblib' in the 'data' folder 
* For the vaccine efficacy simulations it uses the 'rt.csv' file in the 'data' folder
* If the date is 2020-11-17, the generated predictions are persisted as 'DataGrid_2020-11-17_Scored.csv' in the 'data' folder

## feature_post_proc.py

* An extension of the experimental feature importance calculation which is used to generate the feature importance table displayed on the UI
* Currently not scheduled because of the planned enhancement. Run manually when feature importances are recalculated

## vaccine_dict.py

* This script generates the 'vac_mul_dict.joblib' file in the 'data' folder. The dictionary contains vaccine efficacy specific multiplier values for each state

## scenario_dict.py

* This script generates the 'policy_dict.joblib' and 'policy_vac_dict.joblib'  files in the 'data' folder. The dictionaries contain all possible permutation scenarios of human controllable features for generating simulations